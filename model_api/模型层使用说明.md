
# ModelAPI 使用文档

## 简介

`ModelAPI` 类提供了一个统一的接口，用于与不同的语言模型进行交互，包括 GLM-4、GPT4o 和 Qwen 家族的模型。它简化了向这些模型发送请求和获取响应的过程。

本手册将详细说明如何使用 `ModelAPI` 类，包括所有参数的类型和作用。所有参数均通过一个 JSON 对象传入，以便更方便地使用。

## 参数概览

所有需要的参数都通过一个 JSON 对象传递，包括类的初始化参数和方法的调用参数。以下是所有可用参数的列表。

### 参数列表

| 参数名        | 类型    | 作用                                                                                                                                           |
|---------------|---------|------------------------------------------------------------------------------------------------------------------------------------------------|
| model_family  | `str`   | 模型家族名称，可选值为 `"glm-4"`、`"gpt4o"` 或以 `"qwen"` 开头的模型家族名称。                                                                  |
| api_key       | `str`   | 用于验证身份的 API 密钥。                                                                                                                       |
| base_url      | `str`   | *(可选)* API 端点的基 URL。如果未提供，将根据 `model_family` 自动设置。                                                                          |
| api_version   | `str`   | *(可选)* API 版本，特别是对于 GPT4o 模型需要指定此参数。                                                                                         |
| text          | `str`   | 要分析或处理的文本内容。                                                                                                                       |
| prompt        | `str`   | 用于指导模型响应的提示或指令。                                                                                                                  |
| model         | `str`   | 要使用的具体模型名称。对于 GPT4o，这应该是部署名，例如 `"soikit-test"`。                                                                         |
| max_tokens    | `int`   | *(可选)* 生成的最大令牌数，默认为 `1000`。                                                                                                      |
| n             | `int`   | *(可选)* 要生成的响应数量，默认为 `1`。                                                                                                         |
| temperature   | `float` | *(可选)* 采样温度，控制生成文本的随机性，默认为 `0.7`。                                                                                         |

### 参数详解

- **model_family**：决定使用哪个模型客户端以及使用哪个基 URL。必须是支持的模型家族之一。
  - **GLM-4**：支持多种子模型，详情请参考 [GLM-4 模型详情](https://open.bigmodel.cn/dev/api/normal-model/glm-4)。
  - **GPT4o**：使用 Azure OpenAI 平台进行部署，只能通过部署名调用，当前部署名为 `"soikit-test"`。
  - **Qwen**：支持多种模型，详情请参考 [Qwen 模型详情](https://help.aliyun.com/zh/model-studio/developer-reference/compatibility-of-openai-with-dashscope)。

- **api_key**：用于访问模型服务的唯一 API 密钥。请确保您拥有要使用的模型家族的正确密钥。

- **base_url**：API 端点的基 URL。如果未提供，类将根据 `model_family` 自动分配适当的基 URL。

- **api_version**：在使用 GPT4o 模型时需要指定的 API 版本。

- **text**：您希望模型分析或生成响应的主要内容。

- **prompt**：指导模型如何处理 `text` 的指令或上下文，可以包含特定的指令或格式要求。

- **model**：模型家族中的具体模型名称，因模型家族而异：
  - **GLM-4**：可选子模型包括 `"glm-4"`、`"glm-4-flash"` 等。
  - **GPT4o**：由于在 Azure OpenAI 上部署，必须提供部署名，当前为 `"soikit-test"`。
  - **Qwen**：请参考官方文档中的具体模型名称。

- **max_tokens**：*(可选)* 生成的最大令牌数，控制响应的长度。

- **n**：*(可选)* 要生成的响应数量。

- **temperature**：*(可选)* 采样温度，控制生成文本的随机性。较高的值会使输出更随机，较低的值会使输出更确定。

## 使用方法

### 调用方式

使用 `ModelAPI` 类时，您可以将所有参数封装在一个 JSON 对象中，然后进行一次性调用。以下是一个示例：

```python
# 导入必要的库
from model_api import ModelAPI  # 假设您的类保存在 model_api.py 文件中

# 定义参数
params = {
    "model_family": "glm-4",
    "api_key": "your_glm4_api_key",
    "text": "这是待分析的示例文本。",
    "prompt": "请分析以下文本：",
    "model": "glm-4-flash",
    "max_tokens": 1000,
    "n": 1,
    "temperature": 0.7
}

# 创建 ModelAPI 实例并调用 analyze_text 方法
model_api = ModelAPI(**params)
result = model_api.analyze_text()
print("Result:", result)
```

### 说明

- **参数传递**：所有参数都通过解包 `params` 字典的方式传入，确保所有必填参数都在 JSON 对象中提供。

- **方法调用**：实例化 `ModelAPI` 后，直接调用 `analyze_text()` 方法，无需额外参数。

## 返回值

`analyze_text` 方法返回一个包含模型响应的字符串。

| 返回类型 | 说明                                 |
|----------|--------------------------------------|
| `str`    | 模型生成的响应文本，通常为 JSON 格式。 |

## 详细示例

以下是一个完整的示例，展示如何使用一个 JSON 对象来传递所有参数，并获取模型的响应。

```python
# 导入 ModelAPI 类
from model_api_handler import ModelAPI

# 定义参数
params = {
    "model_family": "glm-4",
    "api_key": "08bd304ed5c588b2c9cb534405241f0e.jPN6gjmvlBe2q1ZZ",
    "text": "它分别种了什么树呢？谁来说说？于凯，你来说说看。你慢讲啊。嗯，然后呢？",
    "prompt": "后面的'待分析文本'是一段师生对话，其中，学生话语已经剔除，只保留老师话语，请对老师的话语进行分析...",
    "model": "glm-4-flash",
    "max_tokens": 1000,
    "n": 1,
    "temperature": 0.7
}

# 创建 ModelAPI 实例并调用方法
model_api = ModelAPI(**params)
result = model_api.analyze_text()
print("Result:", result)
```

## 额外信息

- **GLM-4 模型**：支持多种子模型，详情请参考 [GLM-4 模型详情](https://open.bigmodel.cn/dev/api/normal-model/glm-4)。

- **GPT4o 模型**：使用 Azure OpenAI 平台进行部署，只能通过部署名调用，当前部署名为 `"soikit-test"`。使用该模型时，需要指定 `api_version` 参数。

- **Qwen 模型**：支持 Qwen 家族的多种模型，详情请参考 [Qwen 模型详情](https://help.aliyun.com/zh/model-studio/developer-reference/compatibility-of-openai-with-dashscope)。

## 错误处理

如果提供了不支持的 `model_family`，类将抛出 `ValueError`，提示不支持的模型家族。

```python
raise ValueError(f"Unsupported model family: {self.model_family}")
```

请确保您提供的 `model_family` 是以下支持的模型家族之一：`"glm-4"`、`"gpt4o"` 或以 `"qwen"` 开头的模型家族名称。

## 依赖项

- `ModelAPI` 类依赖于 `openai` 包，请确保已安装：

```bash
pip install openai
```

## 注意事项

- **API 密钥安全**：请勿在共享代码或公共仓库中暴露您的 API 密钥。

- **参数一致性**：在使用 GPT4o 模型时，务必提供正确的 api_version 和 model（部署名）。

- **响应格式**：模型的响应通常为 JSON 格式，具体取决于您在 prompt 中的指令。

## 总结

通过将所有参数封装在一个 JSON 对象中，ModelAPI 类提供了更加简洁和统一的接口，方便您与不同的语言模型进行交互。请根据您的需求，正确设置参数，以获得最佳的模型响应。